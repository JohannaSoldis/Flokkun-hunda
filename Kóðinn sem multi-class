import tarfile
import os
import random
import cv2
from PIL import Image
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from skimage.transform import resize
import tensorflow as tf
from keras.models import Sequential
from keras.models import Model
from keras.models import load_model
from keras.layers import Dense, Flatten, Dropout
from keras.callbacks import ModelCheckpoint
from keras.callbacks import EarlyStopping
from keras.callbacks import CSVLogger
from keras.callbacks import ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input
from keras.layers import Flatten, Dense, Dropout

from google.colab import drive
drive.mount('/content/drive')

folder_path = "/content/drive/MyDrive/VOFFVOFF3" #VOFFVOFF
os.chdir('/content/drive/MyDrive/VOFFVOFF3')

# Prófunargögnin (testing data)

folder2_path = "/content/drive/MyDrive/VOFFVOFF3_test"
os.chdir('/content/drive/MyDrive/VOFFVOFF3_test')

img_dir = '/content/drive/MyDrive/VOFFVOFF3'
test_dir = '/content/drive/MyDrive/VOFFVOFF3_test'

img_width, img_height = 224, 224
# Úr samanburðarmódelinu
channels = 3
batch_size = 120 
num_images= 50
image_arr_size= img_width * img_height * channels

img_files = os.listdir(img_dir)
print('Þjálfunargögnin: ', img_files)

test_files = os.listdir(test_dir)
print('Prófunargögnin: ', test_files)

# Splitta í train og validation gögn. Einnig velja stærð og fínpússa áður en það er fittað

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20, 
    width_shift_range=0.2, 
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    validation_split=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

valid_datagen = ImageDataGenerator(
    rescale= 1./255, 
    validation_split=0.2, 
)

train_generator = train_datagen.flow_from_directory(
        img_dir,
        target_size=(224, 224),
        batch_size=32,  
        class_mode='categorical',  # Change class_mode to 'categorical'
        subset='training', #bætti við svo það splitti í train og val..
        shuffle= True #bætti
)

test_datagen = ImageDataGenerator(rescale=1./255) #ÉG fitta ekki þessi gögn - annars er ég að overfitta

test_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=(224, 224),
        batch_size=32,
        class_mode='binary',
        shuffle=True,
        seed=1337)
 
 import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

img_dir = '/content/drive/MyDrive/VOFFVOFF3'  # Change this to the path of your dataset
input_shape = (224, 224, 3)

# Generate batches of augmented data for the validation set
val_generator = valid_datagen.flow_from_directory(
    img_dir,
    target_size=input_shape[:2],
    batch_size=32,
    class_mode='categorical',  # Change class_mode to 'categorical'
    subset='validation', # Split dataset into validation set
    shuffle=False
)

# Define the model architecture
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(3, activation='softmax')  # Change the output layer to have 3 units and 'softmax' activation
])

early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1)

# Compile the model
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples/train_generator.batch_size,
    epochs=100,
    validation_data=val_generator,
    #callbacks=[early_stop, reduce_lr],
    validation_steps=val_generator.samples/val_generator.batch_size
)

plt.subplot()
plt.title('Model Accuracy')
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['Training Accuracy','Validation Accuracy'])
plt.savefig('baseline_acc_epoch.png', transparent= False, bbox_inches= 'tight', dpi= 900)
plt.show()

plt.title('Model Loss')
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend(['Training Loss','Validation Loss'])
plt.savefig('baseline_loss_epoch.png', transparent= False, bbox_inches= 'tight', dpi= 900)
plt.show()

from keras.models import load_model

# Meta módelið á validation gögnin
score = model.evaluate(val_generator, steps=len(val_generator))

print("Validation Loss:", score[0]) 
print("Validation Accuracy:", score[1])

# Meta módelið á validation gögnin
score = model.evaluate(test_generator, steps=len(test_generator))

print("Test Loss:", score[0])
print("Test Accuracy:", score[1])
