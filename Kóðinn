import tarfile
import os
import random
from PIL import Image
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from skimage.transform import resize
import tensorflow as tf
from keras.applications import VGG16
from keras.models import Sequential
from keras.models import Model
from keras.models import load_model
from keras.layers import Dense, Flatten, Dropout
from keras.callbacks import ModelCheckpoint
from keras.callbacks import EarlyStopping
from keras.callbacks import CSVLogger
from keras.callbacks import ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator
from keras.applications.vgg16 import VGG16
from keras.layers import Flatten, Dense, Dropout

from google.colab import drive
drive.mount('/content/drive')

folder_path = "/content/drive/MyDrive/Hundar" #VOFFVOFF
os.chdir('/content/drive/MyDrive/Hundar')

# Prófunargögnin (testing data)

folder2_path = "/content/drive/MyDrive/Hundar_test"
os.chdir('/content/drive/MyDrive/Hundar_test')

from PIL import Image

for file in os.listdir():
    if file.endswith(".jpg"):
        image = Image.open(file)

img_dir = '/content/drive/MyDrive/Hundar'
test_dir = '/content/drive/MyDrive/Hundar_test'

img_width, img_height = 224, 224
# Úr samanburðarmódelinu
channels = 3
batch_size = 120 #Minnka/stækka þetta svo model.fit taki ekki heila eilíf var í 64
num_images= 50
image_arr_size= img_width * img_height * channels

img_files = os.listdir(img_dir)
print('Þjálfunargögnin: ', img_files)

test_files = os.listdir(test_dir)
print('Prófunargögnin: ', test_files)

# Splitta í train og validation gögn

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20, 
    width_shift_range=0.2, 
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    validation_split=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

valid_datagen = ImageDataGenerator(
    rescale= 1./255, 
    validation_split=0.2, 
)

train_generator = train_datagen.flow_from_directory(
        img_dir,
        target_size=(224, 224),
        batch_size=32,  
        class_mode='binary',
        subset='training', #bætti við svo það splitti í train og val..
        shuffle= True, #bætti við
        seed= 1337 #bætti við
    )

validation_generator = valid_datagen.flow_from_directory(
        img_dir,
        target_size=(224, 224),
        batch_size=32,
        class_mode='binary',
        subset='validation', #bætti við
        shuffle= True, #bætti við
        seed= 1337 #bætti við
    )
    
# Síðan prófunargögnin:

test_datagen = ImageDataGenerator(rescale=1./255) #ÉG fitta ekki þessi gögn - annars er ég að overfitta

test_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=(224, 224),
        batch_size=32,
        class_mode='binary',
        shuffle=True,
        seed=1337)
        
# VGG-16

input_shape = (224, 224, 3)

vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Frysti pre-trained lögin
for layer in vgg16_base.layers:
    layer.trainable = False

# Bætti við nýjum lögum á pre-trained lögin
x = Flatten()(vgg16_base.output)
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(1, activation='sigmoid')(x)

model = Model(inputs=vgg16_base.input, outputs=predictions) #Loka módelið

# Til að ég sé ekki að overfitta
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1)

model.compile(loss='binary_crossentropy',
              optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),
              metrics=['accuracy']) 
              
# Til að sjá tauganetið
SVG(model_to_dot(model).create(prog='dot', format='svg'))
plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True, expand_nested=True)

model.summary()

history = model.fit_generator(
      train_generator,
      steps_per_epoch=train_generator.samples/train_generator.batch_size ,
      epochs=30,
      validation_data=validation_generator,
      validation_steps=validation_generator.samples/validation_generator.batch_size,
      callbacks=[early_stop, reduce_lr],
      verbose=1)

plt.figure(figsize=(12, 8))
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model history')

plt.xlabel('epoch')
plt.legend(['train_acc', 'val_acc', 'train_loss', 'val_loss'], loc='upper left')

plt.show()

plt.subplot()
plt.title('Model Accuracy')
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['Training Accuracy','Validation Accuracy'])
plt.savefig('baseline_acc_epoch.png', transparent= False, bbox_inches= 'tight', dpi= 900)
plt.show()

plt.title('Model Loss')
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend(['Training Loss','Validation Loss'])
plt.savefig('baseline_loss_epoch.png', transparent= False, bbox_inches= 'tight', dpi= 900)
plt.show()

# Meta accuracy út frá validation gögnunum 
score = model.evaluate(validation_generator, steps=len(validation_generator))

print("Validation Loss:", score[0]) 
print("Validation Accuracy:", score[1])

# Meta accuracy út frá test gögnunum 
score = model.evaluate(test_generator, steps=len(test_generator))

print("Test Loss:", score[0])
print("Test Accuracy:", score[1])


# EKKI BÚIN AÐ KEYRA - ER AÐ REYNA AÐ PLOTTA

predictions = model.predict(validation_generator, verbose=1) # verbose shows us how long there is to go
predictions

predictions.shape

print(predictions[0])
print(f"Max value (probability of prediction): {np.max(predictions[0])}") # the max probability value predicted by the model
print(f"Sum: {np.sum(predictions[0])}") # because we used softmax activation in our model, this will be close to 1
print(f"Max index: {np.argmax(predictions[0])}") # the index of where the max value in predictions[0] occurs
print(f"Predicted label: {img_dir[np.argmax(predictions[0])]}") # the predicted label

def get_pred_label(prediction_probabilities):
  """
  Turns an array of prediction probabilities into a label.
  """
  return img_dir[np.argmax(prediction_probabilities)]

# Get a predicted label based on an array of prediction probabilities
pred_label = get_pred_label(predictions[0])
pred_label

import numpy as np

# Define label mapping dictionary or list
label_mapping = {0: "cat", 1: "dog"}

# Iterate over the batches and extract the images and labels
images = []
labels = []
for image_batch, label_batch in validation_generator:
    for image, label in zip(image_batch, label_batch):
        images.append(image)
        labels.append(label_mapping[np.argmax(label)])

# Convert lists to arrays
val_images = np.array(images)
val_labels = np.array(labels)

print(val_images[0], val_labels[0])

def plot_pred(prediction_probabilities, labels, images, n=1):
  """
  View the prediction, ground truth label and image for sample n.
  """
  pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]
  
  # Get the pred label
  pred_label = get_pred_label(pred_prob)
  
  # Plot image & remove ticks
  plt.imshow(image)
  plt.xticks([])
  plt.yticks([])

  # Change the color of the title depending on if the prediction is right or wrong
  if pred_label == true_label:
    color = "green"
  else:
    color = "red"

  plt.title("{} {:2.0f}% ({})".format(pred_label,
                                      np.max(pred_prob)*100,
                                      true_label),
                                      color=color)

plot_pred(prediction_probabilities=predictions,
          labels=val_labels,
          images=val_images)
